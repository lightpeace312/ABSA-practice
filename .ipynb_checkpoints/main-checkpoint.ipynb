{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# file: atae-lstm\n",
    "# author: songyouwei <youwei0314@gmail.com>\n",
    "# Copyright (C) 2018. All Rights Reserved.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "import math\n",
    "import os\n",
    "from model import ATAE_LSTM, AOA\n",
    "from data_utils import build_tokenizer, build_embedding_matrix, ABSADataset\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Arguments for restaurant,ATAE-LSTM\n",
    "# opt = Namespace(\n",
    "#     model_name=\"atae_lstm\",\n",
    "#     dataset='restaurant',#twitter,laptop\n",
    "#     seed=1234,\n",
    "#     optimizer = 'adam',\n",
    "#     initializer = 'xavier_uniform_',\n",
    "#     log_step = 5,\n",
    "#     logdir = 'log',\n",
    "#     embed_dim = 200,\n",
    "#     hidden_dim = 300,\n",
    "#     max_seq_len = 80,\n",
    "#     polarities_dim = 3,\n",
    "#     hops = 3,\n",
    "#     device = None,\n",
    "#     learning_rate = 0.001,\n",
    "#     batch_size = 128,\n",
    "#     l2reg = 0.00001,\n",
    "#     num_epoch = 20,\n",
    "#     dropout = 0,\n",
    "# )\n",
    "# dataset_files = {\n",
    "#     'twitter': {\n",
    "#         'train': './datasets/acl-14-short-data/train.raw',\n",
    "#         'test': './datasets/acl-14-short-data/test.raw'\n",
    "#     },\n",
    "#     'restaurant': {\n",
    "#         'train': './datasets/semeval14/Restaurants_Train.xml.seg',\n",
    "#         'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'\n",
    "#     },\n",
    "#     'laptop': {\n",
    "#         'train': './datasets/semeval14/Laptops_Train.xml.seg',\n",
    "#         'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'\n",
    "#     }\n",
    "# }\n",
    "# input_colses = {\n",
    "#         'atae_lstm': ['text_raw_indices', 'aspect_indices']\n",
    "#         'aoa': ['text_raw_indices', 'aspect_indices']\n",
    "#     }\n",
    "# initializers = {\n",
    "#         'xavier_uniform_': torch.nn.init.xavier_uniform_,\n",
    "#         'xavier_normal_': torch.nn.init.xavier_normal,\n",
    "#         'orthogonal_': torch.nn.init.orthogonal_,\n",
    "#     }\n",
    "# optimizers = {\n",
    "#         'adadelta': torch.optim.Adadelta,  # default lr=1.0\n",
    "#         'adagrad': torch.optim.Adagrad,  # default lr=0.01\n",
    "#         'adam': torch.optim.Adam,  # default lr=0.001\n",
    "#         'adamax': torch.optim.Adamax,  # default lr=0.002\n",
    "#         'asgd': torch.optim.ASGD,  # default lr=0.01\n",
    "#         'rmsprop': torch.optim.RMSprop,  # default lr=0.01\n",
    "#         'sgd': torch.optim.SGD,\n",
    "#     }\n",
    "# opt.inputs_cols = input_colses['atae_lstm']\n",
    "# opt.dataset_file = dataset_files[opt.dataset]\n",
    "# opt.initializer = initializers[opt.initializer]\n",
    "# opt.optimizer = optimizers[opt.optimizer]\n",
    "# # opt.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# opt.device = torch.device('cpu')\n",
    "\n",
    "# opt.model_class=ATAE_LSTM\n",
    "# # Set seed for reproducability\n",
    "# np.random.seed(opt.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for restaurant,AOA\n",
    "opt = Namespace(\n",
    "    model_name=\"aoa\",\n",
    "    dataset='restaurant',#twitter,laptop\n",
    "    seed=1234,\n",
    "    optimizer = 'adam',\n",
    "    initializer = 'xavier_uniform_',\n",
    "    log_step = 5,\n",
    "    logdir = 'log',\n",
    "    embed_dim = 200,\n",
    "    hidden_dim = 300,\n",
    "    max_seq_len = 80,\n",
    "    polarities_dim = 3,\n",
    "    hops = 3,\n",
    "    device = None,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 128,\n",
    "    l2reg = 0.0001,#0.00001\n",
    "    num_epoch = 20,\n",
    "    dropout = 0.2,\n",
    ")\n",
    "dataset_files = {\n",
    "    'twitter': {\n",
    "        'train': './datasets/acl-14-short-data/train.raw',\n",
    "        'test': './datasets/acl-14-short-data/test.raw'\n",
    "    },\n",
    "    'restaurant': {\n",
    "        'train': './datasets/semeval14/Restaurants_Train.xml.seg',\n",
    "        'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'\n",
    "    },\n",
    "    'laptop': {\n",
    "        'train': './datasets/semeval14/Laptops_Train.xml.seg',\n",
    "        'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'\n",
    "    }\n",
    "}\n",
    "input_colses = {\n",
    "        'atae_lstm': ['text_raw_indices', 'aspect_indices'],\n",
    "        'aoa': ['text_raw_indices', 'aspect_indices']\n",
    "    }\n",
    "initializers = {\n",
    "        'xavier_uniform_': torch.nn.init.xavier_uniform_,\n",
    "        'xavier_normal_': torch.nn.init.xavier_normal,\n",
    "        'orthogonal_': torch.nn.init.orthogonal_,\n",
    "    }\n",
    "optimizers = {\n",
    "        'adadelta': torch.optim.Adadelta,  # default lr=1.0\n",
    "        'adagrad': torch.optim.Adagrad,  # default lr=0.01\n",
    "        'adam': torch.optim.Adam,  # default lr=0.001\n",
    "        'adamax': torch.optim.Adamax,  # default lr=0.002\n",
    "        'asgd': torch.optim.ASGD,  # default lr=0.01\n",
    "        'rmsprop': torch.optim.RMSprop,  # default lr=0.01\n",
    "        'sgd': torch.optim.SGD,\n",
    "    }\n",
    "opt.inputs_cols = input_colses['atae_lstm']\n",
    "opt.dataset_file = dataset_files[opt.dataset]\n",
    "opt.initializer = initializers[opt.initializer]\n",
    "opt.optimizer = optimizers[opt.optimizer]\n",
    "# opt.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "opt.device = torch.device('cpu')\n",
    "\n",
    "opt.model_class=AOA\n",
    "# Set seed for reproducability\n",
    "np.random.seed(opt.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Instructor:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "\n",
    "        \n",
    "        tokenizer = build_tokenizer(\n",
    "            fnames=[opt.dataset_file['train'], opt.dataset_file['test']],\n",
    "            max_seq_len=opt.max_seq_len,\n",
    "            dat_fname='{0}_tokenizer.dat'.format(opt.dataset))\n",
    "        embedding_matrix = build_embedding_matrix(\n",
    "            word2idx=tokenizer.word2idx,\n",
    "            embed_dim=opt.embed_dim,\n",
    "            em_fname='{0}_{1}_embedding_matrix.dat'.format(str(opt.embed_dim), opt.dataset),\n",
    "            ev_fpath='../../data/embedding')\n",
    "        self.model = opt.model_class(embedding_matrix, opt).to(opt.device)\n",
    "\n",
    "        trainset = ABSADataset(opt.dataset_file['train'], tokenizer)\n",
    "        testset = ABSADataset(opt.dataset_file['test'], tokenizer)\n",
    "        self.train_data_loader = DataLoader(dataset=trainset, batch_size=opt.batch_size, shuffle=True)\n",
    "        self.test_data_loader = DataLoader(dataset=testset, batch_size=opt.batch_size, shuffle=False)\n",
    "\n",
    "        if opt.device.type == 'cuda':\n",
    "            print(\"cuda memory allocated:\", torch.cuda.memory_allocated(device=opt.device.index))\n",
    "        self._print_args()\n",
    "\n",
    "    def _print_args(self):\n",
    "        n_trainable_params, n_nontrainable_params = 0, 0\n",
    "        for p in self.model.parameters():\n",
    "            n_params = torch.prod(torch.tensor(p.shape))\n",
    "            if p.requires_grad:\n",
    "                n_trainable_params += n_params\n",
    "            else:\n",
    "                n_nontrainable_params += n_params\n",
    "        print('n_trainable_params: {0}, n_nontrainable_params: {1}'.format(n_trainable_params, n_nontrainable_params))\n",
    "        print('> training arguments:')\n",
    "        for arg in vars(self.opt):\n",
    "            print('>>> {0}: {1}'.format(arg, getattr(self.opt, arg)))\n",
    "\n",
    "    def _reset_params(self):\n",
    "        for child in self.model.children():\n",
    "#             if type(child) != BertModel:  # skip bert params (with unfreezed bert)\n",
    "            for p in child.parameters():\n",
    "                if p.requires_grad:\n",
    "                    if len(p.shape) > 1:\n",
    "                        self.opt.initializer(p)\n",
    "                    else:\n",
    "                        stdv = 1. / math.sqrt(p.shape[0])\n",
    "                        torch.nn.init.uniform_(p, a=-stdv, b=stdv)\n",
    "\n",
    "    def _train(self, criterion, optimizer, max_test_acc_overall=0):\n",
    "        writer = SummaryWriter(log_dir=self.opt.logdir)\n",
    "        max_test_acc = 0\n",
    "        max_f1 = 0\n",
    "        global_step = 0\n",
    "        for epoch in range(self.opt.num_epoch):\n",
    "            print('>' * 100)\n",
    "            print('epoch: ', epoch)\n",
    "            n_correct, n_total = 0, 0\n",
    "            for i_batch, sample_batched in enumerate(self.train_data_loader):\n",
    "                global_step += 1\n",
    "\n",
    "                # switch model to training mode, clear gradient accumulators\n",
    "                self.model.train()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                inputs = [sample_batched[col].to(self.opt.device) for col in self.opt.inputs_cols]\n",
    "                outputs = self.model(inputs)\n",
    "                targets = sample_batched['polarity'].to(self.opt.device)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if global_step % self.opt.log_step == 0:\n",
    "                    n_correct += (torch.argmax(outputs, -1) == targets).sum().item()\n",
    "                    n_total += len(outputs)\n",
    "                    train_acc = n_correct / n_total\n",
    "\n",
    "                    test_acc, f1 = self._evaluate_acc_f1()\n",
    "                    if test_acc > max_test_acc:\n",
    "                        max_test_acc = test_acc\n",
    "                        if test_acc > max_test_acc_overall:\n",
    "                            if not os.path.exists('state_dict'):\n",
    "                                os.mkdir('state_dict')\n",
    "                            path = 'state_dict/{0}_{1}_acc{2}'.format(self.opt.model_name, self.opt.dataset, round(test_acc, 4))\n",
    "                            torch.save(self.model.state_dict(), path)\n",
    "                            print('>> saved: ' + path)\n",
    "                    if f1 > max_f1:\n",
    "                        max_f1 = f1\n",
    "\n",
    "                    writer.add_scalar('loss', loss, global_step)\n",
    "                    writer.add_scalar('acc', train_acc, global_step)\n",
    "                    writer.add_scalar('test_acc', test_acc, global_step)\n",
    "                    print('loss: {:.4f}, acc: {:.4f}, test_acc: {:.4f}, f1: {:.4f}'.format(loss.item(), train_acc, test_acc, f1))\n",
    "\n",
    "        writer.close()\n",
    "        return max_test_acc, max_f1\n",
    "\n",
    "    def _evaluate_acc_f1(self):\n",
    "        # switch model to evaluation mode\n",
    "        self.model.eval()\n",
    "        n_test_correct, n_test_total = 0, 0\n",
    "        t_targets_all, t_outputs_all = None, None\n",
    "        with torch.no_grad():\n",
    "            for t_batch, t_sample_batched in enumerate(self.test_data_loader):\n",
    "                t_inputs = [t_sample_batched[col].to(opt.device) for col in self.opt.inputs_cols]\n",
    "                t_targets = t_sample_batched['polarity'].to(opt.device)\n",
    "                t_outputs = self.model(t_inputs)\n",
    "\n",
    "                n_test_correct += (torch.argmax(t_outputs, -1) == t_targets).sum().item()\n",
    "                n_test_total += len(t_outputs)\n",
    "\n",
    "                if t_targets_all is None:\n",
    "                    t_targets_all = t_targets\n",
    "                    t_outputs_all = t_outputs\n",
    "                else:\n",
    "                    t_targets_all = torch.cat((t_targets_all, t_targets), dim=0)\n",
    "                    t_outputs_all = torch.cat((t_outputs_all, t_outputs), dim=0)\n",
    "\n",
    "        test_acc = n_test_correct / n_test_total\n",
    "        f1 = metrics.f1_score(t_targets_all.cpu(), torch.argmax(t_outputs_all, -1).cpu(), labels=[0, 1, 2], average='macro')\n",
    "        return test_acc, f1\n",
    "\n",
    "    def run(self, repeats=1):\n",
    "        # Loss and Optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        _params = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        optimizer = self.opt.optimizer(_params, lr=self.opt.learning_rate, weight_decay=self.opt.l2reg)\n",
    "\n",
    "        max_test_acc_overall = 0\n",
    "        max_f1_overall = 0\n",
    "        for i in range(repeats):\n",
    "            print('repeat: ', i)\n",
    "            self._reset_params()\n",
    "            max_test_acc, max_f1 = self._train(criterion, optimizer, max_test_acc_overall=max_test_acc_overall)\n",
    "            print('max_test_acc: {0}     max_f1: {1}'.format(max_test_acc, max_f1))\n",
    "            max_test_acc_overall = max(max_test_acc, max_test_acc_overall)\n",
    "            max_f1_overall = max(max_f1, max_f1_overall)\n",
    "            print('#' * 100)\n",
    "        print(\"max_test_acc_overall:\", max_test_acc_overall)\n",
    "        print(\"max_f1_overall:\", max_f1_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: restaurant_tokenizer.dat\n",
      "loading embedding_matrix: 200_restaurant_embedding_matrix.dat\n",
      "n_trainable_params: 2411403, n_nontrainable_params: 917000\n",
      "> training arguments:\n",
      ">>> model_name: aoa\n",
      ">>> dataset: restaurant\n",
      ">>> seed: 1234\n",
      ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
      ">>> initializer: <function xavier_uniform_ at 0x00000107CCF2F1E0>\n",
      ">>> log_step: 5\n",
      ">>> logdir: log\n",
      ">>> embed_dim: 200\n",
      ">>> hidden_dim: 300\n",
      ">>> max_seq_len: 80\n",
      ">>> polarities_dim: 3\n",
      ">>> hops: 3\n",
      ">>> device: cpu\n",
      ">>> learning_rate: 0.001\n",
      ">>> batch_size: 128\n",
      ">>> l2reg: 1e-05\n",
      ">>> num_epoch: 20\n",
      ">>> dropout: 0\n",
      ">>> inputs_cols: ['text_raw_indices', 'aspect_indices']\n",
      ">>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}\n",
      ">>> model_class: <class 'model.AOA'>\n"
     ]
    }
   ],
   "source": [
    "ins = Instructor(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat:  0\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Users\\xrd03\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> saved: state_dict/aoa_restaurant_acc0.6491\n",
      "loss: 1.0265, acc: 0.5000, test_acc: 0.6491, f1: 0.2844\n",
      ">> saved: state_dict/aoa_restaurant_acc0.6527\n",
      "loss: 0.9546, acc: 0.5625, test_acc: 0.6527, f1: 0.2856\n",
      ">> saved: state_dict/aoa_restaurant_acc0.6616\n",
      "loss: 0.9777, acc: 0.5599, test_acc: 0.6616, f1: 0.3108\n",
      ">> saved: state_dict/aoa_restaurant_acc0.6955\n",
      "loss: 0.8279, acc: 0.5820, test_acc: 0.6955, f1: 0.4674\n",
      ">> saved: state_dict/aoa_restaurant_acc0.6973\n",
      "loss: 0.8167, acc: 0.5922, test_acc: 0.6973, f1: 0.4493\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  1\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7036\n",
      "loss: 0.8583, acc: 0.6484, test_acc: 0.7036, f1: 0.4977\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7232\n",
      "loss: 0.7753, acc: 0.6680, test_acc: 0.7232, f1: 0.5755\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7304\n",
      "loss: 0.8213, acc: 0.6536, test_acc: 0.7304, f1: 0.5483\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7321\n",
      "loss: 0.8494, acc: 0.6445, test_acc: 0.7321, f1: 0.5489\n",
      "loss: 0.6404, acc: 0.6625, test_acc: 0.7214, f1: 0.5095\n",
      "loss: 0.7500, acc: 0.6693, test_acc: 0.7259, f1: 0.5709\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  2\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7348\n",
      "loss: 0.6470, acc: 0.7031, test_acc: 0.7348, f1: 0.5430\n",
      "loss: 0.6799, acc: 0.7070, test_acc: 0.7348, f1: 0.5909\n",
      "loss: 0.7436, acc: 0.7031, test_acc: 0.7250, f1: 0.5013\n",
      "loss: 0.7128, acc: 0.7051, test_acc: 0.7312, f1: 0.5595\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7562\n",
      "loss: 0.6542, acc: 0.7078, test_acc: 0.7562, f1: 0.6103\n",
      "loss: 0.7775, acc: 0.7057, test_acc: 0.7518, f1: 0.6063\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  3\n",
      "loss: 0.6728, acc: 0.7031, test_acc: 0.7411, f1: 0.5751\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7571\n",
      "loss: 0.5372, acc: 0.7500, test_acc: 0.7571, f1: 0.6327\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7634\n",
      "loss: 0.7341, acc: 0.7161, test_acc: 0.7634, f1: 0.6439\n",
      "loss: 0.7614, acc: 0.7109, test_acc: 0.7527, f1: 0.5862\n",
      "loss: 0.7442, acc: 0.7063, test_acc: 0.7509, f1: 0.6212\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7696\n",
      "loss: 0.6072, acc: 0.7148, test_acc: 0.7696, f1: 0.6219\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  4\n",
      "loss: 0.6180, acc: 0.7344, test_acc: 0.7562, f1: 0.5947\n",
      ">> saved: state_dict/aoa_restaurant_acc0.775\n",
      "loss: 0.6267, acc: 0.7305, test_acc: 0.7750, f1: 0.6398\n",
      "loss: 0.4346, acc: 0.7760, test_acc: 0.7670, f1: 0.6215\n",
      "loss: 0.7099, acc: 0.7598, test_acc: 0.7554, f1: 0.6060\n",
      "loss: 0.5465, acc: 0.7625, test_acc: 0.7625, f1: 0.6461\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7848\n",
      "loss: 0.5303, acc: 0.7651, test_acc: 0.7848, f1: 0.6755\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  5\n",
      "loss: 0.6163, acc: 0.7500, test_acc: 0.7741, f1: 0.6372\n",
      "loss: 0.5503, acc: 0.7695, test_acc: 0.7705, f1: 0.6356\n",
      "loss: 0.6179, acc: 0.7604, test_acc: 0.7598, f1: 0.6507\n",
      "loss: 0.5420, acc: 0.7539, test_acc: 0.7554, f1: 0.5954\n",
      "loss: 0.4300, acc: 0.7703, test_acc: 0.7509, f1: 0.6020\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  6\n",
      "loss: 0.5774, acc: 0.7891, test_acc: 0.7661, f1: 0.6411\n",
      "loss: 0.5226, acc: 0.7734, test_acc: 0.7705, f1: 0.6735\n",
      "loss: 0.5519, acc: 0.7786, test_acc: 0.7625, f1: 0.6070\n",
      "loss: 0.5647, acc: 0.7754, test_acc: 0.7616, f1: 0.6252\n",
      "loss: 0.4195, acc: 0.7859, test_acc: 0.7777, f1: 0.6468\n",
      "loss: 0.4342, acc: 0.8008, test_acc: 0.7705, f1: 0.6627\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  7\n",
      "loss: 0.4480, acc: 0.8281, test_acc: 0.7661, f1: 0.6441\n",
      "loss: 0.4809, acc: 0.8125, test_acc: 0.7616, f1: 0.6410\n",
      "loss: 0.4413, acc: 0.8047, test_acc: 0.7696, f1: 0.6525\n",
      "loss: 0.3635, acc: 0.8223, test_acc: 0.7598, f1: 0.6417\n",
      "loss: 0.5373, acc: 0.8063, test_acc: 0.7464, f1: 0.6245\n",
      "loss: 0.5480, acc: 0.8008, test_acc: 0.7795, f1: 0.6644\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  8\n",
      "loss: 0.3619, acc: 0.8750, test_acc: 0.7750, f1: 0.6630\n",
      "loss: 0.4383, acc: 0.8555, test_acc: 0.7634, f1: 0.6346\n",
      "loss: 0.4548, acc: 0.8411, test_acc: 0.7679, f1: 0.6781\n",
      "loss: 0.4098, acc: 0.8457, test_acc: 0.7688, f1: 0.6349\n",
      "loss: 0.4614, acc: 0.8453, test_acc: 0.7768, f1: 0.6769\n",
      "loss: 0.5032, acc: 0.8372, test_acc: 0.7679, f1: 0.6533\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  9\n",
      "loss: 0.2981, acc: 0.8828, test_acc: 0.7670, f1: 0.6642\n",
      "loss: 0.2901, acc: 0.8711, test_acc: 0.7670, f1: 0.6549\n",
      "loss: 0.2535, acc: 0.8932, test_acc: 0.7580, f1: 0.6468\n",
      "loss: 0.4119, acc: 0.8750, test_acc: 0.7714, f1: 0.6610\n",
      "loss: 0.4559, acc: 0.8641, test_acc: 0.7679, f1: 0.6587\n",
      "loss: 0.5205, acc: 0.8614, test_acc: 0.7786, f1: 0.6844\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  10\n",
      "loss: 0.3352, acc: 0.9062, test_acc: 0.7750, f1: 0.6633\n",
      "loss: 0.4177, acc: 0.8789, test_acc: 0.7661, f1: 0.6325\n",
      "loss: 0.3768, acc: 0.8646, test_acc: 0.7759, f1: 0.6897\n",
      "loss: 0.3818, acc: 0.8613, test_acc: 0.7652, f1: 0.6405\n",
      "loss: 0.2608, acc: 0.8672, test_acc: 0.7589, f1: 0.6545\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  11\n",
      "loss: 0.3270, acc: 0.8906, test_acc: 0.7723, f1: 0.6777\n",
      "loss: 0.2371, acc: 0.8984, test_acc: 0.7723, f1: 0.6455\n",
      "loss: 0.2995, acc: 0.8880, test_acc: 0.7777, f1: 0.6775\n",
      "loss: 0.3112, acc: 0.8809, test_acc: 0.7723, f1: 0.6807\n",
      "loss: 0.3562, acc: 0.8812, test_acc: 0.7652, f1: 0.6453\n",
      "loss: 0.3342, acc: 0.8880, test_acc: 0.7732, f1: 0.6874\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  12\n",
      "loss: 0.2522, acc: 0.9375, test_acc: 0.7688, f1: 0.6595\n",
      "loss: 0.3008, acc: 0.9336, test_acc: 0.7661, f1: 0.6699\n",
      "loss: 0.2259, acc: 0.9245, test_acc: 0.7696, f1: 0.6550\n",
      "loss: 0.3328, acc: 0.9082, test_acc: 0.7777, f1: 0.6719\n",
      "loss: 0.3006, acc: 0.9031, test_acc: 0.7812, f1: 0.6890\n",
      "loss: 0.2810, acc: 0.9010, test_acc: 0.7714, f1: 0.6620\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  13\n",
      "loss: 0.3060, acc: 0.8828, test_acc: 0.7536, f1: 0.6342\n",
      "loss: 0.2414, acc: 0.9062, test_acc: 0.7607, f1: 0.6408\n",
      "loss: 0.2552, acc: 0.9010, test_acc: 0.7643, f1: 0.6587\n",
      "loss: 0.1827, acc: 0.9102, test_acc: 0.7696, f1: 0.6525\n",
      "loss: 0.1861, acc: 0.9156, test_acc: 0.7777, f1: 0.6754\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7857\n",
      "loss: 0.2256, acc: 0.9128, test_acc: 0.7857, f1: 0.6821\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  14\n",
      "loss: 0.2289, acc: 0.9297, test_acc: 0.7705, f1: 0.6933\n",
      "loss: 0.2057, acc: 0.9297, test_acc: 0.7625, f1: 0.6591\n",
      "loss: 0.2087, acc: 0.9271, test_acc: 0.7857, f1: 0.6727\n",
      "loss: 0.2989, acc: 0.9141, test_acc: 0.7714, f1: 0.6684\n",
      "loss: 0.2369, acc: 0.9109, test_acc: 0.7679, f1: 0.6597\n",
      "loss: 0.1246, acc: 0.9127, test_acc: 0.7625, f1: 0.6581\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  15\n",
      "loss: 0.1898, acc: 0.9375, test_acc: 0.7598, f1: 0.6344\n",
      "loss: 0.2370, acc: 0.9297, test_acc: 0.7661, f1: 0.6566\n",
      "loss: 0.1434, acc: 0.9349, test_acc: 0.7714, f1: 0.6764\n",
      "loss: 0.2248, acc: 0.9297, test_acc: 0.7607, f1: 0.6343\n",
      "loss: 0.2309, acc: 0.9281, test_acc: 0.7705, f1: 0.6825\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  16\n",
      "loss: 0.1383, acc: 0.9453, test_acc: 0.7732, f1: 0.6668\n",
      "loss: 0.1980, acc: 0.9258, test_acc: 0.7777, f1: 0.6717\n",
      "loss: 0.1725, acc: 0.9271, test_acc: 0.7670, f1: 0.6667\n",
      "loss: 0.2615, acc: 0.9238, test_acc: 0.7634, f1: 0.6591\n",
      "loss: 0.1660, acc: 0.9281, test_acc: 0.7598, f1: 0.6485\n",
      "loss: 0.2019, acc: 0.9310, test_acc: 0.7696, f1: 0.6713\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  17\n",
      "loss: 0.1573, acc: 0.9766, test_acc: 0.7750, f1: 0.6747\n",
      "loss: 0.0957, acc: 0.9766, test_acc: 0.7732, f1: 0.6741\n",
      "loss: 0.2086, acc: 0.9609, test_acc: 0.7696, f1: 0.6710\n",
      "loss: 0.2538, acc: 0.9492, test_acc: 0.7696, f1: 0.6787\n",
      "loss: 0.2715, acc: 0.9453, test_acc: 0.7634, f1: 0.6447\n",
      "loss: 0.2285, acc: 0.9453, test_acc: 0.7643, f1: 0.6634\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  18\n",
      "loss: 0.1349, acc: 0.9688, test_acc: 0.7652, f1: 0.6726\n",
      "loss: 0.1540, acc: 0.9492, test_acc: 0.7696, f1: 0.6614\n",
      "loss: 0.1221, acc: 0.9557, test_acc: 0.7634, f1: 0.6639\n",
      "loss: 0.1603, acc: 0.9492, test_acc: 0.7714, f1: 0.6751\n",
      "loss: 0.1204, acc: 0.9531, test_acc: 0.7723, f1: 0.6789\n",
      "loss: 0.1410, acc: 0.9518, test_acc: 0.7616, f1: 0.6431\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  19\n",
      "loss: 0.1404, acc: 0.9375, test_acc: 0.7670, f1: 0.6739\n",
      "loss: 0.1536, acc: 0.9531, test_acc: 0.7679, f1: 0.6778\n",
      "loss: 0.0921, acc: 0.9531, test_acc: 0.7625, f1: 0.6521\n",
      "loss: 0.1813, acc: 0.9531, test_acc: 0.7732, f1: 0.6714\n",
      "loss: 0.1754, acc: 0.9516, test_acc: 0.7670, f1: 0.6733\n",
      "loss: 0.0809, acc: 0.9533, test_acc: 0.7652, f1: 0.6672\n",
      "max_test_acc: 0.7857142857142857     max_f1: 0.6933051655911623\n",
      "####################################################################################################\n",
      "repeat:  1\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  0\n",
      "loss: 1.1682, acc: 0.2188, test_acc: 0.3411, f1: 0.2464\n",
      "loss: 0.9978, acc: 0.3828, test_acc: 0.6179, f1: 0.2896\n",
      "loss: 1.0093, acc: 0.4401, test_acc: 0.6473, f1: 0.2864\n",
      "loss: 1.0196, acc: 0.4512, test_acc: 0.6429, f1: 0.2875\n",
      "loss: 1.0737, acc: 0.4453, test_acc: 0.6375, f1: 0.3183\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  1\n",
      "loss: 1.0037, acc: 0.5156, test_acc: 0.6464, f1: 0.3125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7a353d873816>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-0b981f1a56d8>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, repeats)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'repeat: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0mmax_test_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_f1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_test_acc_overall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_test_acc_overall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'max_test_acc: {0}     max_f1: {1}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_test_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_f1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mmax_test_acc_overall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_test_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_test_acc_overall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-0b981f1a56d8>\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, criterion, optimizer, max_test_acc_overall)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\xrd03\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\xrd03\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ins.run(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
