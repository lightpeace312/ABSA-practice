{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# file: atae-lstm\n",
    "# author: songyouwei <youwei0314@gmail.com>\n",
    "# Copyright (C) 2018. All Rights Reserved.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "import math\n",
    "import os\n",
    "from model import ATAE_LSTM, AOA\n",
    "from data_utils import build_tokenizer, build_embedding_matrix, ABSADataset\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Arguments for restaurant,ATAE-LSTM\n",
    "# opt = Namespace(\n",
    "#     model_name=\"atae_lstm\",\n",
    "#     dataset='restaurant',#twitter,laptop\n",
    "#     seed=1234,\n",
    "#     optimizer = 'adam',\n",
    "#     initializer = 'xavier_uniform_',\n",
    "#     log_step = 5,\n",
    "#     logdir = 'log',\n",
    "#     embed_dim = 200,\n",
    "#     hidden_dim = 300,\n",
    "#     max_seq_len = 80,\n",
    "#     polarities_dim = 3,\n",
    "#     hops = 3,\n",
    "#     device = None,\n",
    "#     learning_rate = 0.001,\n",
    "#     batch_size = 128,\n",
    "#     l2reg = 0.00001,\n",
    "#     num_epoch = 20,\n",
    "#     dropout = 0,\n",
    "# )\n",
    "# dataset_files = {\n",
    "#     'twitter': {\n",
    "#         'train': './datasets/acl-14-short-data/train.raw',\n",
    "#         'test': './datasets/acl-14-short-data/test.raw'\n",
    "#     },\n",
    "#     'restaurant': {\n",
    "#         'train': './datasets/semeval14/Restaurants_Train.xml.seg',\n",
    "#         'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'\n",
    "#     },\n",
    "#     'laptop': {\n",
    "#         'train': './datasets/semeval14/Laptops_Train.xml.seg',\n",
    "#         'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'\n",
    "#     }\n",
    "# }\n",
    "# input_colses = {\n",
    "#         'atae_lstm': ['text_raw_indices', 'aspect_indices']\n",
    "#         'aoa': ['text_raw_indices', 'aspect_indices']\n",
    "#     }\n",
    "# initializers = {\n",
    "#         'xavier_uniform_': torch.nn.init.xavier_uniform_,\n",
    "#         'xavier_normal_': torch.nn.init.xavier_normal,\n",
    "#         'orthogonal_': torch.nn.init.orthogonal_,\n",
    "#     }\n",
    "# optimizers = {\n",
    "#         'adadelta': torch.optim.Adadelta,  # default lr=1.0\n",
    "#         'adagrad': torch.optim.Adagrad,  # default lr=0.01\n",
    "#         'adam': torch.optim.Adam,  # default lr=0.001\n",
    "#         'adamax': torch.optim.Adamax,  # default lr=0.002\n",
    "#         'asgd': torch.optim.ASGD,  # default lr=0.01\n",
    "#         'rmsprop': torch.optim.RMSprop,  # default lr=0.01\n",
    "#         'sgd': torch.optim.SGD,\n",
    "#     }\n",
    "# opt.inputs_cols = input_colses['atae_lstm']\n",
    "# opt.dataset_file = dataset_files[opt.dataset]\n",
    "# opt.initializer = initializers[opt.initializer]\n",
    "# opt.optimizer = optimizers[opt.optimizer]\n",
    "# # opt.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# opt.device = torch.device('cpu')\n",
    "\n",
    "# opt.model_class=ATAE_LSTM\n",
    "# # Set seed for reproducability\n",
    "# np.random.seed(opt.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for restaurant,AOA\n",
    "opt = Namespace(\n",
    "    model_name=\"aoa\",\n",
    "    dataset='restaurant',#twitter,laptop\n",
    "    seed=1234,\n",
    "    optimizer = 'adam',\n",
    "    initializer = 'xavier_uniform_',\n",
    "    log_step = 5,\n",
    "    logdir = 'log',\n",
    "    embed_dim = 200,\n",
    "    hidden_dim = 300,\n",
    "    max_seq_len = 80,\n",
    "    polarities_dim = 3,\n",
    "    hops = 3,\n",
    "    device = None,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 128,\n",
    "    l2reg = 0.0001,#0.00001\n",
    "    num_epoch = 20,\n",
    "    dropout = 0.2,\n",
    ")\n",
    "dataset_files = {\n",
    "    'twitter': {\n",
    "        'train': './datasets/acl-14-short-data/train.raw',\n",
    "        'test': './datasets/acl-14-short-data/test.raw'\n",
    "    },\n",
    "    'restaurant': {\n",
    "        'train': './datasets/semeval14/Restaurants_Train.xml.seg',\n",
    "        'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'\n",
    "    },\n",
    "    'laptop': {\n",
    "        'train': './datasets/semeval14/Laptops_Train.xml.seg',\n",
    "        'test': './datasets/semeval14/Laptops_Test_Gold.xml.seg'\n",
    "    }\n",
    "}\n",
    "input_colses = {\n",
    "        'atae_lstm': ['text_raw_indices', 'aspect_indices'],\n",
    "        'aoa': ['text_raw_indices', 'aspect_indices']\n",
    "    }\n",
    "initializers = {\n",
    "        'xavier_uniform_': torch.nn.init.xavier_uniform_,\n",
    "        'xavier_normal_': torch.nn.init.xavier_normal,\n",
    "        'orthogonal_': torch.nn.init.orthogonal_,\n",
    "    }\n",
    "optimizers = {\n",
    "        'adadelta': torch.optim.Adadelta,  # default lr=1.0\n",
    "        'adagrad': torch.optim.Adagrad,  # default lr=0.01\n",
    "        'adam': torch.optim.Adam,  # default lr=0.001\n",
    "        'adamax': torch.optim.Adamax,  # default lr=0.002\n",
    "        'asgd': torch.optim.ASGD,  # default lr=0.01\n",
    "        'rmsprop': torch.optim.RMSprop,  # default lr=0.01\n",
    "        'sgd': torch.optim.SGD,\n",
    "    }\n",
    "opt.inputs_cols = input_colses['atae_lstm']\n",
    "opt.dataset_file = dataset_files[opt.dataset]\n",
    "opt.initializer = initializers[opt.initializer]\n",
    "opt.optimizer = optimizers[opt.optimizer]\n",
    "# opt.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "opt.device = torch.device('cpu')\n",
    "\n",
    "opt.model_class=AOA\n",
    "# Set seed for reproducability\n",
    "np.random.seed(opt.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Instructor:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "\n",
    "        \n",
    "        tokenizer = build_tokenizer(\n",
    "            fnames=[opt.dataset_file['train'], opt.dataset_file['test']],\n",
    "            max_seq_len=opt.max_seq_len,\n",
    "            dat_fname='{0}_tokenizer.dat'.format(opt.dataset))\n",
    "        embedding_matrix = build_embedding_matrix(\n",
    "            word2idx=tokenizer.word2idx,\n",
    "            embed_dim=opt.embed_dim,\n",
    "            em_fname='{0}_{1}_embedding_matrix.dat'.format(str(opt.embed_dim), opt.dataset),\n",
    "            ev_fpath='../../data/embedding')\n",
    "        self.model = opt.model_class(embedding_matrix, opt).to(opt.device)\n",
    "\n",
    "        trainset = ABSADataset(opt.dataset_file['train'], tokenizer)\n",
    "        testset = ABSADataset(opt.dataset_file['test'], tokenizer)\n",
    "        self.train_data_loader = DataLoader(dataset=trainset, batch_size=opt.batch_size, shuffle=True)\n",
    "        self.test_data_loader = DataLoader(dataset=testset, batch_size=opt.batch_size, shuffle=False)\n",
    "\n",
    "        if opt.device.type == 'cuda':\n",
    "            print(\"cuda memory allocated:\", torch.cuda.memory_allocated(device=opt.device.index))\n",
    "        self._print_args()\n",
    "\n",
    "    def _print_args(self):\n",
    "        n_trainable_params, n_nontrainable_params = 0, 0\n",
    "        for p in self.model.parameters():\n",
    "            n_params = torch.prod(torch.tensor(p.shape))\n",
    "            if p.requires_grad:\n",
    "                n_trainable_params += n_params\n",
    "            else:\n",
    "                n_nontrainable_params += n_params\n",
    "        print('n_trainable_params: {0}, n_nontrainable_params: {1}'.format(n_trainable_params, n_nontrainable_params))\n",
    "        print('> training arguments:')\n",
    "        for arg in vars(self.opt):\n",
    "            print('>>> {0}: {1}'.format(arg, getattr(self.opt, arg)))\n",
    "\n",
    "    def _reset_params(self):\n",
    "        for child in self.model.children():\n",
    "#             if type(child) != BertModel:  # skip bert params (with unfreezed bert)\n",
    "            for p in child.parameters():\n",
    "                if p.requires_grad:\n",
    "                    if len(p.shape) > 1:\n",
    "                        self.opt.initializer(p)\n",
    "                    else:\n",
    "                        stdv = 1. / math.sqrt(p.shape[0])\n",
    "                        torch.nn.init.uniform_(p, a=-stdv, b=stdv)\n",
    "\n",
    "    def _train(self, criterion, optimizer, max_test_acc_overall=0):\n",
    "        writer = SummaryWriter(log_dir=self.opt.logdir)\n",
    "        max_test_acc = 0\n",
    "        max_f1 = 0\n",
    "        global_step = 0\n",
    "        for epoch in range(self.opt.num_epoch):\n",
    "            print('>' * 100)\n",
    "            print('epoch: ', epoch)\n",
    "            n_correct, n_total = 0, 0\n",
    "            for i_batch, sample_batched in enumerate(self.train_data_loader):\n",
    "                global_step += 1\n",
    "\n",
    "                # switch model to training mode, clear gradient accumulators\n",
    "                self.model.train()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                inputs = [sample_batched[col].to(self.opt.device) for col in self.opt.inputs_cols]\n",
    "                outputs = self.model(inputs)\n",
    "                targets = sample_batched['polarity'].to(self.opt.device)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if global_step % self.opt.log_step == 0:\n",
    "                    n_correct += (torch.argmax(outputs, -1) == targets).sum().item()\n",
    "                    n_total += len(outputs)\n",
    "                    train_acc = n_correct / n_total\n",
    "\n",
    "                    test_acc, f1 = self._evaluate_acc_f1()\n",
    "                    if test_acc > max_test_acc:\n",
    "                        max_test_acc = test_acc\n",
    "                        if test_acc > max_test_acc_overall:\n",
    "                            if not os.path.exists('state_dict'):\n",
    "                                os.mkdir('state_dict')\n",
    "                            path = 'state_dict/{0}_{1}_acc{2}'.format(self.opt.model_name, self.opt.dataset, round(test_acc, 4))\n",
    "                            torch.save(self.model.state_dict(), path)\n",
    "                            print('>> saved: ' + path)\n",
    "                    if f1 > max_f1:\n",
    "                        max_f1 = f1\n",
    "\n",
    "                    writer.add_scalar('loss', loss, global_step)\n",
    "                    writer.add_scalar('acc', train_acc, global_step)\n",
    "                    writer.add_scalar('test_acc', test_acc, global_step)\n",
    "                    print('loss: {:.4f}, acc: {:.4f}, test_acc: {:.4f}, f1: {:.4f}'.format(loss.item(), train_acc, test_acc, f1))\n",
    "\n",
    "        writer.close()\n",
    "        return max_test_acc, max_f1\n",
    "\n",
    "    def _evaluate_acc_f1(self):\n",
    "        # switch model to evaluation mode\n",
    "        self.model.eval()\n",
    "        n_test_correct, n_test_total = 0, 0\n",
    "        t_targets_all, t_outputs_all = None, None\n",
    "        with torch.no_grad():\n",
    "            for t_batch, t_sample_batched in enumerate(self.test_data_loader):\n",
    "                t_inputs = [t_sample_batched[col].to(opt.device) for col in self.opt.inputs_cols]\n",
    "                t_targets = t_sample_batched['polarity'].to(opt.device)\n",
    "                t_outputs = self.model(t_inputs)\n",
    "\n",
    "                n_test_correct += (torch.argmax(t_outputs, -1) == t_targets).sum().item()\n",
    "                n_test_total += len(t_outputs)\n",
    "\n",
    "                if t_targets_all is None:\n",
    "                    t_targets_all = t_targets\n",
    "                    t_outputs_all = t_outputs\n",
    "                else:\n",
    "                    t_targets_all = torch.cat((t_targets_all, t_targets), dim=0)\n",
    "                    t_outputs_all = torch.cat((t_outputs_all, t_outputs), dim=0)\n",
    "\n",
    "        test_acc = n_test_correct / n_test_total\n",
    "        f1 = metrics.f1_score(t_targets_all.cpu(), torch.argmax(t_outputs_all, -1).cpu(), labels=[0, 1, 2], average='macro')\n",
    "        return test_acc, f1\n",
    "\n",
    "    def run(self, repeats=1):\n",
    "        # Loss and Optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        _params = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        optimizer = self.opt.optimizer(_params, lr=self.opt.learning_rate, weight_decay=self.opt.l2reg)\n",
    "\n",
    "        max_test_acc_overall = 0\n",
    "        max_f1_overall = 0\n",
    "        for i in range(repeats):\n",
    "            print('repeat: ', i)\n",
    "            self._reset_params()\n",
    "            max_test_acc, max_f1 = self._train(criterion, optimizer, max_test_acc_overall=max_test_acc_overall)\n",
    "            print('max_test_acc: {0}     max_f1: {1}'.format(max_test_acc, max_f1))\n",
    "            max_test_acc_overall = max(max_test_acc, max_test_acc_overall)\n",
    "            max_f1_overall = max(max_f1, max_f1_overall)\n",
    "            print('#' * 100)\n",
    "        print(\"max_test_acc_overall:\", max_test_acc_overall)\n",
    "        print(\"max_f1_overall:\", max_f1_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: restaurant_tokenizer.dat\n",
      "loading embedding_matrix: 200_restaurant_embedding_matrix.dat\n",
      "n_trainable_params: 2411403, n_nontrainable_params: 917000\n",
      "> training arguments:\n",
      ">>> model_name: aoa\n",
      ">>> dataset: restaurant\n",
      ">>> seed: 1234\n",
      ">>> optimizer: <class 'torch.optim.adam.Adam'>\n",
      ">>> initializer: <function xavier_uniform_ at 0x00000107CCF2F1E0>\n",
      ">>> log_step: 5\n",
      ">>> logdir: log\n",
      ">>> embed_dim: 200\n",
      ">>> hidden_dim: 300\n",
      ">>> max_seq_len: 80\n",
      ">>> polarities_dim: 3\n",
      ">>> hops: 3\n",
      ">>> device: cpu\n",
      ">>> learning_rate: 0.001\n",
      ">>> batch_size: 128\n",
      ">>> l2reg: 1e-05\n",
      ">>> num_epoch: 20\n",
      ">>> dropout: 0\n",
      ">>> inputs_cols: ['text_raw_indices', 'aspect_indices']\n",
      ">>> dataset_file: {'train': './datasets/semeval14/Restaurants_Train.xml.seg', 'test': './datasets/semeval14/Restaurants_Test_Gold.xml.seg'}\n",
      ">>> model_class: <class 'model.AOA'>\n"
     ]
    }
   ],
   "source": [
    "ins = Instructor(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat:  0\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  0\n",
      ">> saved: state_dict/aoa_restaurant_acc0.65\n",
      "loss: 0.9300, acc: 0.6172, test_acc: 0.6500, f1: 0.2626\n",
      ">> saved: state_dict/aoa_restaurant_acc0.6536\n",
      "loss: 0.8817, acc: 0.6289, test_acc: 0.6536, f1: 0.2799\n",
      ">> saved: state_dict/aoa_restaurant_acc0.6679\n",
      "loss: 0.8468, acc: 0.6302, test_acc: 0.6679, f1: 0.3621\n",
      ">> saved: state_dict/aoa_restaurant_acc0.6857\n",
      "loss: 0.8365, acc: 0.6289, test_acc: 0.6857, f1: 0.4196\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7098\n",
      "loss: 0.8084, acc: 0.6281, test_acc: 0.7098, f1: 0.5329\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  1\n",
      ">> saved: state_dict/aoa_restaurant_acc0.717\n",
      "loss: 0.6640, acc: 0.7422, test_acc: 0.7170, f1: 0.5264\n",
      "loss: 0.8300, acc: 0.6758, test_acc: 0.6982, f1: 0.5208\n",
      "loss: 0.6979, acc: 0.6745, test_acc: 0.6982, f1: 0.4131\n",
      "loss: 0.8112, acc: 0.6699, test_acc: 0.6982, f1: 0.4807\n",
      "loss: 0.7630, acc: 0.6703, test_acc: 0.7152, f1: 0.4699\n",
      "loss: 0.8860, acc: 0.6602, test_acc: 0.6964, f1: 0.4286\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  2\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7277\n",
      "loss: 0.8095, acc: 0.6641, test_acc: 0.7277, f1: 0.5767\n",
      "loss: 0.7732, acc: 0.6797, test_acc: 0.7223, f1: 0.5458\n",
      "loss: 0.6505, acc: 0.6771, test_acc: 0.7250, f1: 0.4960\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7446\n",
      "loss: 0.6412, acc: 0.6895, test_acc: 0.7446, f1: 0.5829\n",
      "loss: 0.7756, acc: 0.6734, test_acc: 0.7339, f1: 0.6092\n",
      "loss: 0.5958, acc: 0.6901, test_acc: 0.7446, f1: 0.5866\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  3\n",
      "loss: 0.6815, acc: 0.7578, test_acc: 0.7411, f1: 0.6080\n",
      "loss: 0.6211, acc: 0.7812, test_acc: 0.7446, f1: 0.5696\n",
      "loss: 0.7028, acc: 0.7500, test_acc: 0.7384, f1: 0.5246\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7562\n",
      "loss: 0.6251, acc: 0.7539, test_acc: 0.7562, f1: 0.6097\n",
      "loss: 0.7471, acc: 0.7469, test_acc: 0.7509, f1: 0.5832\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7616\n",
      "loss: 0.6879, acc: 0.7383, test_acc: 0.7616, f1: 0.6391\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  4\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7732\n",
      "loss: 0.6217, acc: 0.7266, test_acc: 0.7732, f1: 0.6466\n",
      "loss: 0.5978, acc: 0.7266, test_acc: 0.7634, f1: 0.6002\n",
      "loss: 0.6275, acc: 0.7083, test_acc: 0.7634, f1: 0.6461\n",
      "loss: 0.5551, acc: 0.7324, test_acc: 0.7679, f1: 0.6327\n",
      "loss: 0.6958, acc: 0.7281, test_acc: 0.7598, f1: 0.6063\n",
      "loss: 0.4872, acc: 0.7304, test_acc: 0.7652, f1: 0.6370\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  5\n",
      "loss: 0.5671, acc: 0.7578, test_acc: 0.7580, f1: 0.6015\n",
      "loss: 0.5517, acc: 0.7422, test_acc: 0.7688, f1: 0.6360\n",
      "loss: 0.5754, acc: 0.7448, test_acc: 0.7688, f1: 0.6547\n",
      ">> saved: state_dict/aoa_restaurant_acc0.775\n",
      "loss: 0.4855, acc: 0.7559, test_acc: 0.7750, f1: 0.6648\n",
      "loss: 0.5201, acc: 0.7578, test_acc: 0.7732, f1: 0.6594\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  6\n",
      "loss: 0.4879, acc: 0.8359, test_acc: 0.7580, f1: 0.6244\n",
      "loss: 0.5439, acc: 0.8047, test_acc: 0.7688, f1: 0.6504\n",
      "loss: 0.5066, acc: 0.8021, test_acc: 0.7723, f1: 0.6472\n",
      "loss: 0.5381, acc: 0.7988, test_acc: 0.7696, f1: 0.6685\n",
      "loss: 0.4322, acc: 0.8047, test_acc: 0.7625, f1: 0.6305\n",
      "loss: 0.4030, acc: 0.8112, test_acc: 0.7607, f1: 0.6307\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  7\n",
      ">> saved: state_dict/aoa_restaurant_acc0.783\n",
      "loss: 0.5661, acc: 0.7500, test_acc: 0.7830, f1: 0.6767\n",
      "loss: 0.3959, acc: 0.7930, test_acc: 0.7732, f1: 0.6535\n",
      "loss: 0.4322, acc: 0.8021, test_acc: 0.7804, f1: 0.6825\n",
      "loss: 0.4744, acc: 0.8105, test_acc: 0.7768, f1: 0.6709\n",
      "loss: 0.4743, acc: 0.8125, test_acc: 0.7821, f1: 0.6773\n",
      "loss: 0.3984, acc: 0.8164, test_acc: 0.7795, f1: 0.6574\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  8\n",
      "loss: 0.3861, acc: 0.8281, test_acc: 0.7804, f1: 0.6903\n",
      "loss: 0.5199, acc: 0.7969, test_acc: 0.7750, f1: 0.6506\n",
      "loss: 0.4332, acc: 0.7995, test_acc: 0.7741, f1: 0.6745\n",
      "loss: 0.3941, acc: 0.8047, test_acc: 0.7661, f1: 0.6171\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7839\n",
      "loss: 0.4494, acc: 0.8094, test_acc: 0.7839, f1: 0.6945\n",
      "loss: 0.3600, acc: 0.8164, test_acc: 0.7795, f1: 0.6694\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  9\n",
      "loss: 0.2927, acc: 0.8906, test_acc: 0.7804, f1: 0.6611\n",
      ">> saved: state_dict/aoa_restaurant_acc0.7884\n",
      "loss: 0.3155, acc: 0.8789, test_acc: 0.7884, f1: 0.6872\n",
      "loss: 0.3778, acc: 0.8672, test_acc: 0.7705, f1: 0.6569\n",
      "loss: 0.3891, acc: 0.8594, test_acc: 0.7884, f1: 0.6981\n",
      "loss: 0.3932, acc: 0.8531, test_acc: 0.7830, f1: 0.6729\n",
      "loss: 0.5693, acc: 0.8524, test_acc: 0.7830, f1: 0.6953\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  10\n",
      "loss: 0.2799, acc: 0.8984, test_acc: 0.7759, f1: 0.6607\n",
      "loss: 0.2952, acc: 0.8984, test_acc: 0.7821, f1: 0.6959\n",
      "loss: 0.3291, acc: 0.8906, test_acc: 0.7795, f1: 0.6823\n",
      "loss: 0.2726, acc: 0.8965, test_acc: 0.7839, f1: 0.6783\n",
      "loss: 0.2760, acc: 0.8969, test_acc: 0.7804, f1: 0.6830\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  11\n",
      "loss: 0.3206, acc: 0.8594, test_acc: 0.7616, f1: 0.6077\n",
      "loss: 0.2822, acc: 0.8789, test_acc: 0.7688, f1: 0.6805\n",
      "loss: 0.2941, acc: 0.8776, test_acc: 0.7830, f1: 0.6882\n",
      "loss: 0.4157, acc: 0.8711, test_acc: 0.7661, f1: 0.6344\n",
      "loss: 0.4098, acc: 0.8625, test_acc: 0.7634, f1: 0.6747\n",
      "loss: 0.3749, acc: 0.8633, test_acc: 0.7661, f1: 0.6364\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  12\n",
      "loss: 0.2235, acc: 0.9219, test_acc: 0.7634, f1: 0.6506\n",
      "loss: 0.2295, acc: 0.9141, test_acc: 0.7607, f1: 0.6352\n",
      "loss: 0.4054, acc: 0.9062, test_acc: 0.7696, f1: 0.6458\n",
      "loss: 0.3128, acc: 0.8984, test_acc: 0.7688, f1: 0.6574\n",
      "loss: 0.2223, acc: 0.9000, test_acc: 0.7679, f1: 0.6408\n",
      "loss: 0.2080, acc: 0.9049, test_acc: 0.7830, f1: 0.6802\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  13\n",
      "loss: 0.2773, acc: 0.9141, test_acc: 0.7688, f1: 0.6549\n",
      "loss: 0.1409, acc: 0.9414, test_acc: 0.7670, f1: 0.6407\n",
      "loss: 0.2093, acc: 0.9323, test_acc: 0.7777, f1: 0.6790\n",
      "loss: 0.2540, acc: 0.9238, test_acc: 0.7723, f1: 0.6562\n",
      "loss: 0.2094, acc: 0.9234, test_acc: 0.7554, f1: 0.6412\n",
      "loss: 0.1870, acc: 0.9258, test_acc: 0.7679, f1: 0.6541\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  14\n",
      "loss: 0.2391, acc: 0.9297, test_acc: 0.7527, f1: 0.6262\n",
      "loss: 0.2225, acc: 0.9219, test_acc: 0.7750, f1: 0.6716\n",
      "loss: 0.2055, acc: 0.9193, test_acc: 0.7812, f1: 0.6801\n",
      "loss: 0.1789, acc: 0.9219, test_acc: 0.7795, f1: 0.6755\n",
      "loss: 0.1356, acc: 0.9266, test_acc: 0.7616, f1: 0.6441\n",
      "loss: 0.1690, acc: 0.9277, test_acc: 0.7705, f1: 0.6647\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  15\n",
      "loss: 0.2337, acc: 0.8906, test_acc: 0.7741, f1: 0.6793\n",
      "loss: 0.2243, acc: 0.9062, test_acc: 0.7670, f1: 0.6650\n",
      "loss: 0.1214, acc: 0.9193, test_acc: 0.7616, f1: 0.6564\n",
      "loss: 0.1471, acc: 0.9258, test_acc: 0.7696, f1: 0.6623\n",
      "loss: 0.1767, acc: 0.9281, test_acc: 0.7857, f1: 0.6832\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  16\n",
      "loss: 0.1079, acc: 0.9844, test_acc: 0.7607, f1: 0.6606\n",
      "loss: 0.1435, acc: 0.9688, test_acc: 0.7562, f1: 0.6412\n",
      "loss: 0.1626, acc: 0.9609, test_acc: 0.7696, f1: 0.6715\n",
      "loss: 0.1543, acc: 0.9570, test_acc: 0.7705, f1: 0.6643\n",
      "loss: 0.1270, acc: 0.9516, test_acc: 0.7759, f1: 0.6689\n",
      "loss: 0.1145, acc: 0.9518, test_acc: 0.7696, f1: 0.6647\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  17\n",
      "loss: 0.2931, acc: 0.9141, test_acc: 0.6777, f1: 0.6267\n",
      "loss: 0.3266, acc: 0.8828, test_acc: 0.7536, f1: 0.6034\n",
      "loss: 0.3009, acc: 0.8828, test_acc: 0.7491, f1: 0.6487\n",
      "loss: 0.2320, acc: 0.8945, test_acc: 0.7554, f1: 0.6637\n",
      "loss: 0.2522, acc: 0.8922, test_acc: 0.7625, f1: 0.6454\n",
      "loss: 0.2454, acc: 0.8919, test_acc: 0.7598, f1: 0.6542\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  18\n",
      "loss: 0.2344, acc: 0.9375, test_acc: 0.7634, f1: 0.6569\n",
      "loss: 0.1572, acc: 0.9414, test_acc: 0.7589, f1: 0.6426\n",
      "loss: 0.2189, acc: 0.9375, test_acc: 0.7616, f1: 0.6541\n",
      "loss: 0.1516, acc: 0.9492, test_acc: 0.7670, f1: 0.6696\n",
      "loss: 0.1565, acc: 0.9516, test_acc: 0.7723, f1: 0.6748\n",
      "loss: 0.1288, acc: 0.9531, test_acc: 0.7661, f1: 0.6681\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  19\n",
      "loss: 0.1797, acc: 0.9297, test_acc: 0.7473, f1: 0.6524\n",
      "loss: 0.2011, acc: 0.9336, test_acc: 0.7509, f1: 0.6400\n",
      "loss: 0.2015, acc: 0.9271, test_acc: 0.7509, f1: 0.6692\n",
      "loss: 0.2079, acc: 0.9258, test_acc: 0.7634, f1: 0.6671\n",
      "loss: 0.3052, acc: 0.9125, test_acc: 0.7679, f1: 0.6541\n",
      "loss: 0.1200, acc: 0.9142, test_acc: 0.7598, f1: 0.6620\n",
      "max_test_acc: 0.7883928571428571     max_f1: 0.6981238015068696\n",
      "####################################################################################################\n",
      "repeat:  1\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  0\n",
      "loss: 1.3130, acc: 0.1562, test_acc: 0.2571, f1: 0.2604\n",
      "loss: 1.1140, acc: 0.2773, test_acc: 0.5902, f1: 0.2987\n",
      "loss: 1.1217, acc: 0.3281, test_acc: 0.6375, f1: 0.3042\n",
      "loss: 1.0338, acc: 0.3770, test_acc: 0.6429, f1: 0.3066\n",
      "loss: 1.0357, acc: 0.3969, test_acc: 0.6205, f1: 0.3198\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  1\n",
      "loss: 1.0741, acc: 0.4609, test_acc: 0.6438, f1: 0.3268\n",
      "loss: 0.9763, acc: 0.5078, test_acc: 0.6536, f1: 0.2968\n",
      "loss: 0.9544, acc: 0.5495, test_acc: 0.6554, f1: 0.2965\n",
      "loss: 0.9978, acc: 0.5469, test_acc: 0.6598, f1: 0.3207\n",
      "loss: 0.8743, acc: 0.5656, test_acc: 0.6670, f1: 0.3294\n",
      "loss: 0.8515, acc: 0.5703, test_acc: 0.6866, f1: 0.3982\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  2\n",
      "loss: 0.7877, acc: 0.7031, test_acc: 0.6795, f1: 0.3709\n",
      "loss: 0.8665, acc: 0.6953, test_acc: 0.6813, f1: 0.4756\n",
      "loss: 0.7921, acc: 0.6875, test_acc: 0.6821, f1: 0.3690\n",
      "loss: 0.8279, acc: 0.6699, test_acc: 0.6973, f1: 0.4450\n",
      "loss: 0.7648, acc: 0.6625, test_acc: 0.7054, f1: 0.4569\n",
      "loss: 0.7542, acc: 0.6628, test_acc: 0.7188, f1: 0.5119\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  3\n",
      "loss: 0.7729, acc: 0.6641, test_acc: 0.7134, f1: 0.4915\n",
      "loss: 0.8135, acc: 0.6914, test_acc: 0.7250, f1: 0.5588\n",
      "loss: 0.7205, acc: 0.6875, test_acc: 0.7277, f1: 0.5198\n",
      "loss: 0.7629, acc: 0.6816, test_acc: 0.7063, f1: 0.4545\n",
      "loss: 0.7535, acc: 0.6797, test_acc: 0.7179, f1: 0.5321\n",
      "loss: 0.6941, acc: 0.6862, test_acc: 0.7161, f1: 0.4944\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  4\n",
      "loss: 0.6963, acc: 0.7188, test_acc: 0.7152, f1: 0.5210\n",
      "loss: 0.7110, acc: 0.7266, test_acc: 0.7223, f1: 0.5535\n",
      "loss: 0.7047, acc: 0.7188, test_acc: 0.7286, f1: 0.5475\n",
      "loss: 0.6714, acc: 0.7207, test_acc: 0.7312, f1: 0.5433\n",
      "loss: 0.6608, acc: 0.7219, test_acc: 0.7241, f1: 0.5991\n",
      "loss: 0.5700, acc: 0.7199, test_acc: 0.7536, f1: 0.5943\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  5\n",
      "loss: 0.7092, acc: 0.6953, test_acc: 0.7348, f1: 0.5235\n",
      "loss: 0.6625, acc: 0.6953, test_acc: 0.7438, f1: 0.5472\n",
      "loss: 0.6391, acc: 0.7161, test_acc: 0.7446, f1: 0.5909\n",
      "loss: 0.7565, acc: 0.6953, test_acc: 0.7375, f1: 0.6061\n",
      "loss: 0.5239, acc: 0.7188, test_acc: 0.7384, f1: 0.5442\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  6\n",
      "loss: 0.7002, acc: 0.6328, test_acc: 0.7071, f1: 0.5634\n",
      "loss: 0.5548, acc: 0.7109, test_acc: 0.7366, f1: 0.5691\n",
      "loss: 0.7030, acc: 0.7161, test_acc: 0.7571, f1: 0.6608\n",
      "loss: 0.6025, acc: 0.7285, test_acc: 0.7438, f1: 0.5575\n",
      "loss: 0.6162, acc: 0.7375, test_acc: 0.7482, f1: 0.5759\n",
      "loss: 0.5246, acc: 0.7435, test_acc: 0.7429, f1: 0.5978\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  7\n",
      "loss: 0.5316, acc: 0.7891, test_acc: 0.7562, f1: 0.6033\n",
      "loss: 0.6013, acc: 0.7734, test_acc: 0.7518, f1: 0.5763\n",
      "loss: 0.5115, acc: 0.7812, test_acc: 0.7571, f1: 0.6056\n",
      "loss: 0.5492, acc: 0.7773, test_acc: 0.7634, f1: 0.6295\n",
      "loss: 0.6669, acc: 0.7609, test_acc: 0.7545, f1: 0.5968\n",
      "loss: 0.6111, acc: 0.7604, test_acc: 0.7580, f1: 0.6159\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  8\n",
      "loss: 0.5402, acc: 0.7422, test_acc: 0.7634, f1: 0.6324\n",
      "loss: 0.5589, acc: 0.7617, test_acc: 0.7554, f1: 0.5868\n",
      "loss: 0.5253, acc: 0.7682, test_acc: 0.7652, f1: 0.6359\n",
      "loss: 0.6648, acc: 0.7578, test_acc: 0.7688, f1: 0.6378\n",
      "loss: 0.5087, acc: 0.7625, test_acc: 0.7634, f1: 0.6167\n",
      "loss: 0.4272, acc: 0.7786, test_acc: 0.7607, f1: 0.6332\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  9\n",
      "loss: 0.3999, acc: 0.8438, test_acc: 0.7634, f1: 0.6300\n",
      "loss: 0.4481, acc: 0.8164, test_acc: 0.7679, f1: 0.6220\n",
      "loss: 0.5367, acc: 0.7891, test_acc: 0.7679, f1: 0.6434\n",
      "loss: 0.5047, acc: 0.7891, test_acc: 0.7589, f1: 0.6170\n",
      "loss: 0.4380, acc: 0.8016, test_acc: 0.7795, f1: 0.6499\n",
      "loss: 0.6493, acc: 0.7982, test_acc: 0.7679, f1: 0.6165\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  10\n",
      "loss: 0.4528, acc: 0.7969, test_acc: 0.7679, f1: 0.6450\n",
      "loss: 0.3921, acc: 0.8242, test_acc: 0.7714, f1: 0.6413\n",
      "loss: 0.3335, acc: 0.8411, test_acc: 0.7777, f1: 0.6713\n",
      "loss: 0.4379, acc: 0.8301, test_acc: 0.7589, f1: 0.6216\n",
      "loss: 0.4877, acc: 0.8328, test_acc: 0.7696, f1: 0.6507\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  11\n",
      "loss: 0.4655, acc: 0.8203, test_acc: 0.7714, f1: 0.6644\n",
      "loss: 0.3747, acc: 0.8242, test_acc: 0.7714, f1: 0.6561\n",
      "loss: 0.3809, acc: 0.8281, test_acc: 0.7750, f1: 0.6570\n",
      "loss: 0.4112, acc: 0.8379, test_acc: 0.7714, f1: 0.6443\n",
      "loss: 0.3491, acc: 0.8375, test_acc: 0.7759, f1: 0.6658\n",
      "loss: 0.3604, acc: 0.8451, test_acc: 0.7679, f1: 0.6396\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  12\n",
      "loss: 0.3645, acc: 0.8438, test_acc: 0.7634, f1: 0.6613\n",
      "loss: 0.4016, acc: 0.8516, test_acc: 0.7562, f1: 0.6127\n",
      "loss: 0.3379, acc: 0.8516, test_acc: 0.7732, f1: 0.6744\n",
      "loss: 0.4157, acc: 0.8535, test_acc: 0.7741, f1: 0.6377\n",
      "loss: 0.3647, acc: 0.8578, test_acc: 0.7679, f1: 0.6748\n",
      "loss: 0.3482, acc: 0.8594, test_acc: 0.7670, f1: 0.6322\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "epoch:  13\n",
      "loss: 0.3167, acc: 0.8750, test_acc: 0.7598, f1: 0.6174\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7a353d873816>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-0b981f1a56d8>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, repeats)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'repeat: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0mmax_test_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_f1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_test_acc_overall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_test_acc_overall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'max_test_acc: {0}     max_f1: {1}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_test_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_f1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mmax_test_acc_overall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_test_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_test_acc_overall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-0b981f1a56d8>\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, criterion, optimizer, max_test_acc_overall)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\xrd03\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Users\\xrd03\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ins.run(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
